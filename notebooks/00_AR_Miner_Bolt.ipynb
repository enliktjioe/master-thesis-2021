{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/enlik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "config = get_config('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = read_csv_from_gdrive(config['csv_input']['bolt_apple'])\n",
    "# total_reviews = len(df2)\n",
    "# unique_users  = ddlen(df2['userName'].unique())\n",
    "# mean = df2['rating'].mean()\n",
    "\n",
    "# print(f'Total English reviews: {total_reviews} \\n')\n",
    "# print(f'Total unique users : {unique_users}')\n",
    "# print(f'Total users who gave multiple reviews: {total_reviews - unique_users}\\n')\n",
    "# print(f'Average rating for this app based on the textual reviews: {round(mean,2)} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP based Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size for swiftkey : 1706\n",
      "Training set Size: 1000\n",
      "Testing set Size: 2000\n",
      "Unlabeling set Size: 3282\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ./AR_Miner/AR_util.py\n",
    "%run ./AR_Miner/AR_reviewInstance.py\n",
    "\n",
    "# Inputs:\n",
    "datasetName = \"swiftkey\" # four apps: facebook, templerun2, swiftkey, tapfish:\n",
    "# datasetName = \"templerun2\" # four apps: facebook, templerun2, swiftkey, tapfish\n",
    "rmStopWords = True # Removing stop words lead to information loss and bad f-score\n",
    "rmRareWords = True # Remove the word with low frequency\n",
    "skParse = False # set skParse True to directly read of the data that has been filtered out\n",
    "\n",
    "# Outputs:\n",
    "if(skParse == False):\n",
    "    trainSet, testSet, unlabelSet, vocabulary = AR_parse(datasetName, rmStopWords, rmRareWords)\n",
    "\n",
    "print('\\n')\n",
    "# trainSet[0].printSelf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more progress, stopping EM at iteration 50\n",
      "Average F-Score for the test data: 0.788007420330797\n",
      "71.22413099999999 seconds\n",
      "Number of informative reviews: 1061\n",
      "Number of uninformative reviews: 2221\n",
      "\n",
      "\n",
      "Review id: 3003 Rating: 1 Content: crash chrome everi minut Ntokens: 4 TS:  Group:  Prob: 0.7745828828324669 label: 1\n",
      "Raw text: crashes chrome every 5 minutes\n",
      "\n",
      "\n",
      "Review id: 3007 Rating: 5 Content: love product Ntokens: 2 TS:  Group:  Prob: 0 label: 0\n",
      "Raw text: love this product\n"
     ]
    }
   ],
   "source": [
    "%run ./AR_Miner/AR_classifier.py\n",
    "import time\n",
    "start_time = time.clock()\n",
    "\n",
    "useSVM = True # SVM is way better than EMNB in the testing\n",
    "if(skParse == False):\n",
    "    if(useSVM == False):\n",
    "#         informRev, informMat = AR_emnb(trainSet, testSet, unlabelSet, vocabulary, datasetName)\n",
    "        informRev, uninformRev, informMat = AR_emnb(trainSet, testSet, unlabelSet, vocabulary, datasetName)\n",
    "    else:\n",
    "#         informRev, informMat = AR_svm(trainSet, testSet, unlabelSet, vocabulary, datasetName)\n",
    "        informRev, uninformRev, informMat = AR_svm(trainSet, testSet, unlabelSet, vocabulary, datasetName)\n",
    "    print(time.clock() - start_time, \"seconds\")\n",
    "    # write the result back to the file (optional)\n",
    "    # AR_writeReviews(informRev, datasetName)\n",
    "    \n",
    "else:\n",
    "    # directly read from the file\n",
    "    informRev, informMat, vocabulary = AR_loadReviews(datasetName)\n",
    "\n",
    "print(\"Number of informative reviews: \" + str(len(informRev)))\n",
    "print(\"Number of uninformative reviews: \" + str(len(uninformRev)))\n",
    "print('\\n')\n",
    "informRev[1].printSelf()\n",
    "print('\\n')\n",
    "uninformRev[5].printSelf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review id: 3137 Rating: 5 Content: simpli brilliant Ntokens: 2 TS:  Group:  Prob: 0 label: 0\n",
      "Raw text: simply brilliant\n"
     ]
    }
   ],
   "source": [
    "uninformRev[90].printSelf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA topic clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./AR_Miner/AR_lda.py\n",
    "\n",
    "# n_topics = 20 # the number of topics\n",
    "# doc_topic, vocab, top_words_list = AR_lda(informMat, vocabulary, n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Algorithms for Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./AR_Miner/AR_ranker.py\n",
    "\n",
    "# wg = [0.85, 0.15]\n",
    "# group_scores, sorted_group_indices = group_rank(doc_topic, wg, informRev)\n",
    "# print('Group scores:\\n' + str(group_scores) + '\\n')\n",
    "# print('Group in order of importance:\\n' + str(sorted_group_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./AR_Miner/AR_textrank.py\n",
    "\n",
    "# AR_tfIdf(informRev)\n",
    "# rankrevText = AR_textrank(doc_topic, informRev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print the top two reviews of the first five groups:\n",
    "# for i in range(5): # number of groups to print\n",
    "#     print(\"Instance review for topic group: \" + str(i))\n",
    "#     for j in range(2): # number of top reviews to print\n",
    "#         r_ind = rankrevText[i][j][0]\n",
    "#         score = rankrevText[i][j][1]\n",
    "#         print(str(j+1) + \"th review \" + \"Text: \" +  informRev[r_ind].text + \" Score: \" + str(score))\n",
    "#     print (\"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./AR_Miner/AR_reviewRanking.py\n",
    "\n",
    "# AR_tfIdf(informRev)\n",
    "# weight = [0.25, 0.25, 0.25, 0.25]\n",
    "# rankrevTopic = instance_ranking(doc_topic, weight, informRev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./AR_Miner/AR_visualization.py\n",
    "\n",
    "# group_count = 10\n",
    "# plot_group_ranking(group_scores, sorted_group_indices, top_words_list, group_count)\n",
    "# print(\"Ranking all the reviews in the first group via text rank\")\n",
    "# plot_instance_ranking(sorted_group_indices[0], informRev, rankrevText, 10)\n",
    "# print(\"Ranking all the reviews in the first group via topic modeling\")\n",
    "# plot_instance_ranking(sorted_group_indices[0], informRev, rankrevTopic, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
